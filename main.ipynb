{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48184bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kennym1/.conda/envs/MA384/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c946e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b980bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      name  size_bytes suffix date_modified  \\\n",
      "0  +----------------------------------.txt        3112   .txt    2025-07-10   \n",
      "1                                .Rhistory        1297           2025-12-22   \n",
      "2                            ._ipp2-source         178           2022-09-07   \n",
      "3      01 PCProcessorMicroarchitecture.pdf      170784   .pdf    2025-03-13   \n",
      "4               01-probability-review.docx       19858  .docx    2025-12-09   \n",
      "\n",
      "  date_created  \n",
      "0   2025-07-10  \n",
      "1   2025-12-22  \n",
      "2   2025-11-04  \n",
      "3   2025-03-13  \n",
      "4   2025-12-09  \n"
     ]
    }
   ],
   "source": [
    "# # Path to Downloads (Windows example)\n",
    "# downloads_path = Path.home() / \"Downloads\"\n",
    "\n",
    "# # Collect file info\n",
    "# data = []\n",
    "# for file in downloads_path.iterdir():\n",
    "#     if file.is_file():\n",
    "#         stat = file.stat()\n",
    "#         data.append({\n",
    "#             \"name\": file.name,\n",
    "#             \"size_bytes\": stat.st_size,\n",
    "#             \"suffix\": file.suffix,\n",
    "#             \"date_modified\": pd.to_datetime(stat.st_mtime, unit=\"s\").strftime(\"%Y-%m-%d\"),\n",
    "#             \"date_created\": pd.to_datetime(stat.st_birthtime, unit=\"s\").strftime(\"%Y-%m-%d\"),\n",
    "#         })\n",
    "\n",
    "# # Convert to DataFrame\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c253d900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      name  size_bytes suffix date_modified  \\\n",
      "0  +----------------------------------.txt        3112   .txt    2025-07-10   \n",
      "1                                .Rhistory        1297    NaN    2025-12-22   \n",
      "2                            ._ipp2-source         178    NaN    2022-09-07   \n",
      "3      01 PCProcessorMicroarchitecture.pdf      170784   .pdf    2025-03-13   \n",
      "4               01-probability-review.docx       19858  .docx    2025-12-09   \n",
      "\n",
      "  date_created  \n",
      "0   2025-07-10  \n",
      "1   2025-12-22  \n",
      "2   2025-11-04  \n",
      "3   2025-03-13  \n",
      "4   2025-12-09  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/kennym1/download_analysis/downloads_info.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5f2664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"downloads_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baa446e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suffix\n",
      ".pdf                                        570\n",
      ".docx                                        68\n",
      ".pptx                                        67\n",
      ".png                                         45\n",
      ".html                                        37\n",
      ".txt                                         26\n",
      ".csv                                         22\n",
      ".sql                                         17\n",
      ".jpg                                         14\n",
      ".jfif                                        11\n",
      ".xlsx                                        10\n",
      ".bmpr                                         9\n",
      ".jpeg                                         8\n",
      ".json                                         6\n",
      ".ans                                          6\n",
      ".in                                           6\n",
      ".py                                           6\n",
      ".v                                            5\n",
      ".java                                         5\n",
      ".ipynb                                        4\n",
      ".log                                          4\n",
      ".c                                            4\n",
      ".tex                                          4\n",
      ".ics                                          3\n",
      ".wav                                          3\n",
      ".js                                           3\n",
      ".rtf                                          2\n",
      ".ini                                          2\n",
      ".doc                                          2\n",
      ".mp4                                          2\n",
      ".iso                                          2\n",
      ".url                                          1\n",
      ".cr_3da527c9-a1c1-4e7b-b6e3-697ca37d4873      1\n",
      ".schem                                        1\n",
      ".tsv                                          1\n",
      ".appinstaller                                 1\n",
      ".lnk                                          1\n",
      ".vsdx                                         1\n",
      ".sof                                          1\n",
      ".vbs                                          1\n",
      ".mw                                           1\n",
      ".cpp                                          1\n",
      ".yankai                                       1\n",
      ".chm                                          1\n",
      ".puml                                         1\n",
      ".UF2                                          1\n",
      ".msix                                         1\n",
      ".env                                          1\n",
      ".whl                                          1\n",
      ".aux                                          1\n",
      ".fdb_latexmk                                  1\n",
      ".fls                                          1\n",
      ".out                                          1\n",
      ".cns                                          1\n",
      ".bak                                          1\n",
      ".es3                                          1\n",
      ".bac                                          1\n",
      ".properties                                   1\n",
      ".do                                           1\n",
      ".mp3                                          1\n",
      ".bibtex                                       1\n",
      ".eml                                          1\n",
      ".latex                                        1\n",
      ".msi                                          1\n",
      ".ogg                                          1\n",
      ".xz                                           1\n",
      ".tmp                                          1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.suffix.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cde1a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Stage 1: Rule-based by extension (instant, no model needed) ---\n",
    "EXTENSION_RULES = {\n",
    "    # Software\n",
    "    \".exe\": \"Software Installer\", \".msi\": \"Software Installer\",\n",
    "    \".iso\": \"Software Installer\", \".dmg\": \"Software Installer\",\n",
    "    \".apk\": \"Software Installer\", \".deb\": \"Software Installer\",\n",
    "    # Media\n",
    "    \".mp4\": \"Media or Entertainment\", \".mkv\": \"Media or Entertainment\",\n",
    "    \".avi\": \"Media or Entertainment\", \".mp3\": \"Media or Entertainment\",\n",
    "    \".wav\": \"Media or Entertainment\", \".flac\": \"Media or Entertainment\",\n",
    "    # Images\n",
    "    \".jpg\": \"Photo or Image\", \".jpeg\": \"Photo or Image\",\n",
    "    \".png\": \"Photo or Image\",  \".gif\": \"Photo or Image\",\n",
    "    \".svg\": \"Photo or Image\",  \".psd\": \"Creative Project\",\n",
    "    # Code / Data\n",
    "    \".py\": \"Dataset or Code\", \".js\": \"Dataset or Code\",\n",
    "    \".csv\": \"Dataset or Code\", \".json\": \"Dataset or Code\",\n",
    "    \".ipynb\": \"Dataset or Code\", \".sql\": \"Dataset or Code\",\n",
    "    # Archives\n",
    "    \".zip\": \"Archive or Backup\", \".rar\": \"Archive or Backup\",\n",
    "    \".tar\": \"Archive or Backup\", \".gz\": \"Archive or Backup\",\n",
    "    \".7z\": \"Archive or Backup\",\n",
    "}\n",
    "\n",
    "# --- Stage 2: NLP zero-shot for ambiguous extensions ---\n",
    "AMBIGUOUS_EXTENSIONS = {\".pdf\", \".docx\", \".doc\", \".txt\", \".pptx\", \".xlsx\", \".xls\"}\n",
    "\n",
    "NLP_LABELS = [\n",
    "    \"Personal Documentation\",\n",
    "    \"Schoolwork\",\n",
    "    \"Financial\",\n",
    "    \"Research Paper\",\n",
    "    \"Creative Project\",\n",
    "    \"Dataset or Code\",\n",
    "    \"Archive or Backup\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d302adde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 106/106 [00:00<00:00, 368.18it/s, Materializing param=pooler.dense.weight]                                     \n",
      "\u001b[1mDebertaV2ForSequenceClassification LOAD REPORT\u001b[0m from: cross-encoder/nli-deberta-v3-small\n",
      "Key                             | Status     |  | \n",
      "--------------------------------+------------+--+-\n",
      "deberta.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\n",
    "        \"zero-shot-classification\",\n",
    "        model=\"cross-encoder/nli-deberta-v3-small\",\n",
    "        device=0,  # remove this line if you don't have a GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e01547a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule-based: 269 files | NLP needed: 743 files\n",
      "                                         name suffix           category\n",
      "0     +----------------------------------.txt   .txt  Archive or Backup\n",
      "1                                   .Rhistory    NaN              Other\n",
      "2                               ._ipp2-source    NaN              Other\n",
      "3         01 PCProcessorMicroarchitecture.pdf   .pdf  Archive or Backup\n",
      "4                  01-probability-review.docx  .docx    Dataset or Code\n",
      "5                01. WPS  PQR SMAW E6013.json  .json    Dataset or Code\n",
      "6                    02 RealCloudComputer.pdf   .pdf    Dataset or Code\n",
      "7                 02-statistical-process.docx  .docx    Dataset or Code\n",
      "8           03 How TI Adopted VLIW in DSP.pdf   .pdf    Dataset or Code\n",
      "9                          03-likelihood.docx  .docx    Dataset or Code\n",
      "10  03485f00-95ad-4b43-9900-5dae10eda43f.jfif  .jfif              Other\n",
      "11              04 BFS and DFS Variations.pdf   .pdf     Research Paper\n",
      "12                    04-updating-priors.docx  .docx    Dataset or Code\n",
      "13                         05-estimation.docx  .docx    Dataset or Code\n",
      "14                               05.06.25.pdf   .pdf    Dataset or Code\n",
      "15                               05.08.25.pdf   .pdf    Dataset or Code\n",
      "16                         06-prediction.docx  .docx    Dataset or Code\n",
      "17                 07-hypothesis-testing.docx  .docx    Dataset or Code\n",
      "18  08 Knuth-Morris-Pratt String Matching.pdf   .pdf  Archive or Backup\n",
      "19                08-constructing-priors.docx  .docx    Dataset or Code\n"
     ]
    }
   ],
   "source": [
    "def classify_with_rules(row) -> str:\n",
    "    ext = row[\"suffix\"].lower() if pd.notna(row[\"suffix\"]) else \"\"\n",
    "    if ext in EXTENSION_RULES:\n",
    "        return EXTENSION_RULES[ext]\n",
    "    if ext in AMBIGUOUS_EXTENSIONS:\n",
    "        return None  # needs NLP\n",
    "    return \"Other\"\n",
    "\n",
    "df[\"category\"] = df.apply(classify_with_rules, axis=1)\n",
    "\n",
    "needs_nlp = df[\"category\"].isna()\n",
    "print(f\"Rule-based: {(~needs_nlp).sum()} files | NLP needed: {needs_nlp.sum()} files\")\n",
    "\n",
    "# Only load the model if there are ambiguous files\n",
    "if needs_nlp.any():\n",
    "    ambiguous_names = df.loc[needs_nlp, \"name\"].tolist()\n",
    "\n",
    "    # Batch inference — much faster than calling one at a time\n",
    "    cleaned = [n.replace(\"_\", \" \").replace(\"-\", \" \").replace(\".\", \" \") for n in ambiguous_names]\n",
    "    results = classifier(cleaned, candidate_labels=NLP_LABELS, batch_size=16)\n",
    "\n",
    "    df.loc[needs_nlp, \"category\"] = [r[\"labels\"][0] for r in results]\n",
    "\n",
    "print(df[[\"name\", \"suffix\", \"category\"]].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4168a237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MA384",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
